{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLHeV9icIk-b"
      },
      "source": [
        "![](https://i.imgur.com/qkg2E2D.png)\n",
        "\n",
        "# Natural Language Processing\n",
        "\n",
        "## Assignment 002 - POS Tagging with Universal Dependencies\n",
        "\n",
        "> Notebook by:\n",
        "> - NLP Course Stuff\n",
        "\n",
        "## Revision History\n",
        "\n",
        "| Version | Date       | User        |Content / Changes                                                   |\n",
        "|---------|------------|-------------|--------------------------------------------------------------------|\n",
        "|  |  |    | |\n",
        "| 0.1.000 | 01/05/2024 | course staff | First version                                                      |\n",
        "|         |            |             |                                                                    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCFoQxO0H0yk"
      },
      "source": [
        "## Overview\n",
        "In this assignment, you will train and evaluate a Part-of-Speech (POS) tagger using data from the Universal Dependencies (UD) project. POS taggers assign parts of speech to each word in a sentence, such as noun, verb, adjective, etc., which are crucial for many natural language processing tasks.\n",
        "\n",
        "## Dataset\n",
        "Utilize the English Web Treebank from the Universal Dependencies project. You can access and explore the dataset [here](https://universaldependencies.org/). For a better understanding of the project and the data format, visit the [introduction page](https://universaldependencies.org/introduction.html).\n",
        "\n",
        "## Tasks Overview\n",
        "\n",
        "#### Part 1: Dataset Preparation\n",
        "- **Objective**: Get the Universal Dependencies dataset ready for the tagging tasks.\n",
        "- **Activities**: Download, preprocess, and format the dataset.\n",
        "\n",
        "#### Part 2: HMM Tagger\n",
        "- **Objective**: Create and assess a POS tagger using the Hidden Markov Model.\n",
        "- **Activities**: Construct, train, and evaluate the HMM tagger.\n",
        "\n",
        "#### Part 3: Feed-Forward Neural Network Tagger\n",
        "- **Objective**: Build a POS tagger using a feed-forward neural network with word embeddings.\n",
        "- **Activities**: Develop and train the model in PyTorch, then evaluate its effectiveness.\n",
        "\n",
        "#### Part 4: NLTK MEMM Tagger\n",
        "- **Objective**: Implement and test a MEMM-based POS tagger using NLTK.\n",
        "- **Activities**: Train the MEMM tagger, then evaluate its performance.\n",
        "\n",
        "#### Part 5: Models' Comparison\n",
        "- **Objective**: Evaluate and contrast the performance of different models.\n",
        "- **Activities**: Address two open-ended questions.\n",
        "\n",
        "\n",
        "## Your Implementation\n",
        "\n",
        "Please create a local copy of this template Colab's Notebook:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1FfXDvRMALIsd-IzPdf_Fn92OLVHjSY9I#scrollTo=JCFoQxO0H0yk)\n",
        "\n",
        "The assignment's instructions are there; follow the notebook.\n",
        "\n",
        "## Submission\n",
        "- **Notebook Link**: Add the URL to your assignment's notebook in the `notebook_link.txt` file, following the format provided in the example.\n",
        "- **Access**: Ensure the link has edit permissions enabled to allow modifications if needed.\n",
        "- **Deadline**: <font color='green'>21/05/2024</font>.\n",
        "- **Platform**: Continue using GitHub for submissions. Push your project to the team repository and monitor the test results under the actions section.\n",
        "\n",
        "Good Luck ðŸ¤—\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iWKz8IfKi5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1541c656-3a59-4459-8b4f-ce8707db74a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for conllutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Prerequisite: Install the conllutils library before proceeding with the tasks\n",
        "!pip install --q conllutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRm7zcfq56HF"
      },
      "outputs": [],
      "source": [
        "# Standard Library Imports\n",
        "import os\n",
        "import random\n",
        "import operator\n",
        "import json\n",
        "from typing import List, Tuple, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "# Data Handling and Numerical Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "from google.colab import files\n",
        "\n",
        "# Machine Learning and Evaluation Libraries\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
        "\n",
        "# Natural Language Processing Libraries\n",
        "import nltk\n",
        "from nltk.tag import tnt\n",
        "from nltk.metrics import ConfusionMatrix, precision, recall, f_measure\n",
        "\n",
        "# Deep Learning Libraries (PyTorch)\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# CoNLL Utilities for Data Handling\n",
        "import conllutils\n",
        "import gensim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH-Xvqip6Teu"
      },
      "source": [
        "# Part 1 - Dataset Preparation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTv6rMt0oIw9"
      },
      "source": [
        "For each package you use, set the random seed to 42."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtM4HY2LoYDn"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "# Set the random seed for Python\n",
        "random.seed(SEED)\n",
        "\n",
        "# Set the random seed for numpy\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Set the random seed for pytorch\n",
        "th.manual_seed(SEED)\n",
        "\n",
        "# If using CUDA (for GPU operations)\n",
        "th.cuda.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuvbl0hooXXx"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "### Step 1: Access the Dataset\n",
        "The GUM dataset, which is part of the English corpora under Universal Dependencies, is specifically curated for academic and research purposes. You can download the dataset directly from the following GitHub repository:\n",
        "\n",
        "[UD English-GUM](https://github.com/UniversalDependencies/UD_English-GUM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsZsyTVC6Sw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d0d6ca-c937-410f-b913-6d3b3ec82467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UD_English-GUM'...\n",
            "remote: Enumerating objects: 6573, done.\u001b[K\n",
            "remote: Counting objects: 100% (1600/1600), done.\u001b[K\n",
            "remote: Compressing objects: 100% (316/316), done.\u001b[K\n",
            "remote: Total 6573 (delta 1484), reused 1394 (delta 1284), pack-reused 4973\u001b[K\n",
            "Receiving objects: 100% (6573/6573), 59.82 MiB | 16.85 MiB/s, done.\n",
            "Resolving deltas: 100% (6118/6118), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/UniversalDependencies/UD_English-GUM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "airorSOzSRm_"
      },
      "source": [
        "### Step 2: Reading the Data\n",
        "We will use the (train/dev/test) files:\n",
        "\n",
        "\n",
        "```\n",
        "UD_English-GUM/en_gum-ud-train.conllu\n",
        "UD_English-GUM/en_gum-ud-dev.conllu\n",
        "UD_English-GUM/en_gum-ud-test.conllu\n",
        "```\n",
        "\n",
        "## CoNLL-U Format\n",
        "They are all formatted in the CoNLL-U format. You may read about it [here](https://universaldependencies.org/format.html). There is a utility library **conllutils**, which can help you read the data into the memory. It has already been installed and imported above.\n",
        "\n",
        "## Task: Create a Read Data Function\n",
        "\n",
        "### Function Specification\n",
        "Create a function named `read_data` that:\n",
        "- Takes a file path to a `.conllu` file as input.\n",
        "- Returns a list of lists, where each inner list represents a sentence.\n",
        "- Each sentence is composed of tuples containing the word ('form') and its corresponding Universal POS tag ('upos').\n",
        "\n",
        "The word is located in the column named 'form' and the POS tag in the column named 'upos' of the CoNLL-U format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkepUJYENXPq"
      },
      "outputs": [],
      "source": [
        "DataType = list[list[tuple[str, str]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYt7poZ3V2LV"
      },
      "outputs": [],
      "source": [
        "def read_data(filepath: str) -> DataType:\n",
        "    \"\"\"\n",
        "    Reads a CoNLL-U formatted file and extracts sentences as lists of (word, POS tag) tuples.\n",
        "\n",
        "    Args:\n",
        "    filepath (str): The path to the .conllu file to be read.\n",
        "\n",
        "    Returns:\n",
        "    List[List[Tuple[str, str]]]: A list of sentences, where each sentence is a list of tuples containing the word and its POS tag.\n",
        "    \"\"\"\n",
        "    output = []\n",
        "    # TO DO ----------------------------------------------------------------------\n",
        "    current_sentence = []\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line.startswith('#'):\n",
        "                continue\n",
        "\n",
        "            line_split = line.split('\\t')\n",
        "            if not line:\n",
        "                if current_sentence:\n",
        "                    output.append(current_sentence)\n",
        "                    current_sentence = []\n",
        "\n",
        "            if len(line_split) > 3:\n",
        "                word_form = line_split[1]\n",
        "                pos_upos = line_split[3]\n",
        "                if pos_upos != '_':\n",
        "                  current_sentence.append((word_form, pos_upos))\n",
        "    # TO DO ----------------------------------------------------------------------\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmRpi7gXknQC"
      },
      "outputs": [],
      "source": [
        "# Run this block once `read_data` is implemented.\n",
        "train_dataset = read_data(\"UD_English-GUM/en_gum-ud-train.conllu\")\n",
        "dev_dataset = read_data(\"UD_English-GUM/en_gum-ud-dev.conllu\")\n",
        "test_dataset = read_data(\"UD_English-GUM/en_gum-ud-test.conllu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of sentences in train_dataset:\", len(train_dataset))\n",
        "print(\"Number of sentences in dev_dataset:\", len(dev_dataset))\n",
        "print(\"Number of sentences in test_dataset:\", len(test_dataset))"
      ],
      "metadata": {
        "id": "2821iVGUiHi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d8af4d-6af1-4aa5-8d7f-9465e4b00737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences in train_dataset: 9521\n",
            "Number of sentences in dev_dataset: 1341\n",
            "Number of sentences in test_dataset: 1285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2E18JUi2YeD"
      },
      "source": [
        "## Task: Create a Vocabulary Generation Function\n",
        "\n",
        "### Function Specification\n",
        "Create a function named `generate_vocabs` for mapping words and tags into unique numbers so that we can use them in the tagging algorithms you will implement below. The function:\n",
        "- Takes a list of sentences as input, where each sentence is composed of tuples containing a word and its corresponding Universal POS tag.\n",
        "- Returns a tuple of two dictionaries:\n",
        "  - The first dictionary maps each unique word to a unique integer.\n",
        "  - The second dictionary maps each unique POS tag to a unique integer.\n",
        "\n",
        "Each word and POS tag should be mapped starting from 0, with each new word or tag encountered receiving the next sequential integer. This function is essential for converting textual data into a numerical format that can be used by tagging algorithms.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j47ImFVyyoO4"
      },
      "outputs": [],
      "source": [
        "def generate_vocabs(datasets: list[DataType]) -> tuple[dict[str, int], dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Generates vocabularies mapping words and tags to unique indices from a list of datasets.\n",
        "\n",
        "    Args:\n",
        "    datasets (list): A list of datasets where each dataset contains sentences formatted as lists of (word, tag) tuples.\n",
        "\n",
        "    Returns:\n",
        "    Tuple[dict[str, int], dict[str, int]]: A tuple of two dictionaries:\n",
        "        - The first dictionary maps each unique word to a unique integer.\n",
        "        - The second dictionary maps each unique POS tag to a unique integer.\n",
        "        Each dictionary includes a special '<<UNK>>' entry mapped to 0 to handle unknown words or tags.\n",
        "    \"\"\"\n",
        "    words_vocab = {\"<<UNK>>\": 0}\n",
        "    tags_vocab = {\"<<UNK>>\": 0}\n",
        "    word_index = 1\n",
        "    tag_index = 1\n",
        "    # TO DO ----------------------------------------------------------------------\n",
        "\n",
        "    for data_set in datasets:\n",
        "        for sentence in data_set:\n",
        "            for tup in sentence:\n",
        "                tup_word = tup[0] # extract the word from the tuple\n",
        "                tup_pos = tup[1] # extract the part of speech from the tuple\n",
        "\n",
        "                try: # test if the word is already in the vocab, if not add it and increment the index\n",
        "                    test = words_vocab[tup_word]\n",
        "                except KeyError:\n",
        "                    words_vocab[tup_word] = word_index\n",
        "                    word_index += 1\n",
        "\n",
        "                try: # test if the tag is already in the tags vocab, if not add it and increment the index\n",
        "                    test = tags_vocab[tup_pos]\n",
        "                except KeyError:\n",
        "                    tags_vocab[tup_pos] = tag_index\n",
        "                    tag_index += 1\n",
        "\n",
        "    # TO DO ----------------------------------------------------------------------\n",
        "    return words_vocab, tags_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwzutNN21Z6m"
      },
      "outputs": [],
      "source": [
        "# Run this block once `generate_vocabs` is implemented.\n",
        "words_vocab, tags_vocab = generate_vocabs([train_dataset, dev_dataset, test_dataset])\n",
        "reversed_words_vocab = {v: k for k, v in words_vocab.items()}\n",
        "reversed_tags_vocab = {v: k for k, v in tags_vocab.items()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of unique words:\", len(words_vocab))\n",
        "print(\"Number of unique tags:\", len(tags_vocab))"
      ],
      "metadata": {
        "id": "1KIOQogITKT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691abe48-6671-4e24-cafd-7451bdfd808b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words: 19874\n",
            "Number of unique tags: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etK9iZIq8i0X"
      },
      "source": [
        "# Part 2 - HMM Tagger\n",
        "\n",
        "### Task Description\n",
        "Implement a class `HMMTagger` to perform POS tagging using a Hidden Markov Model (HMM).\n",
        "\n",
        "### Class Methods\n",
        "- `fit`: This method should compute the transition probabilities matrix (A), emission probabilities matrix (B), and initial state probabilities vector (Pi) based on the training data. These matrices should reflect probabilities of transitions between tags, emissions of words given tags, and initial tag probabilities, respectively.\n",
        "- `inference`: Implement this method to predict the best tag sequence for a given input sentence using the Viterbi decoding algorithm. The Viterbi algorithm is provided below.\n",
        "### Additional Guidance\n",
        "1. **Use of Vocabularies**: Utilize the vocabularies generated in Part 1. These should include a special entry for unknown words and tags (`<<UNK>>` at index 0). The indices in your vocabularies will correspond to the rows and columns of your A, B, and Pi matrices (np.array).\n",
        "2. **Smoothing**: Apply Add-One Smoothing to all probability calculations to avoid zero probabilities. This technique adjusts the frequency counts for each observed event by adding one to each count.\n",
        "3. **Word Conversion**: During inference, convert each word of the input sentence into its corresponding index using the word vocabulary. If a word is not found, use the index for `<<UNK>>`.\n",
        "\n",
        "### Implementation Tips\n",
        "- You can use the vocab dictionaries directly, no need to pass them as a parameter to the functions.\n",
        "- You may add functions to `HMMTagger` as needed.\n",
        "- Ensure that your A, B, and Pi matrices handle unseen words/tags gracefully using the `<<UNK>>` index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpH7GuiQ9L6W"
      },
      "outputs": [],
      "source": [
        "class HMMTagger:\n",
        "  def __init__(self):\n",
        "      \"\"\"\n",
        "      Initializes the HMMTagger class with necessary attributes.\n",
        "      \"\"\"\n",
        "      self._Ï€ = np.zeros(len(tags_vocab))  # Initial state probabilities\n",
        "      self._A = np.zeros((len(tags_vocab), len(tags_vocab)))  # Transition probabilities\n",
        "      self._B = np.zeros((len(tags_vocab), len(words_vocab)))  # Emission probabilities\n",
        "\n",
        "  def fit(self, dataset: DataType):\n",
        "      \"\"\"\n",
        "      Trains the HMM model on the provided dataset.\n",
        "\n",
        "      Args:\n",
        "          dataset (list): The training dataset containing sentences as lists of (word, tag) tuples.\n",
        "      \"\"\"\n",
        "      # TO DO ----------------------------------------------------------------------\n",
        "      for sentence in dataset:\n",
        "          previous_tag_index = None\n",
        "          for i in range(len(sentence)):\n",
        "            word, tag = sentence[i]\n",
        "            word_index = words_vocab.get(word, words_vocab['<<UNK>>']) # get the index of the word from vocab if it exists, otherwise set its index to 0 (index of unk)\n",
        "            tag_index = tags_vocab.get(tag, tags_vocab['<<UNK>>'])# get the index of the tag from vocab if it exists, otherwise set its index to 0 (index of unk)\n",
        "\n",
        "            # initial state probabilities\n",
        "            if i == 0:\n",
        "                self._Ï€[tag_index] += 1\n",
        "\n",
        "            # emission probabilities\n",
        "            self._B[tag_index][word_index] += 1\n",
        "\n",
        "            # transition probabilities\n",
        "            if previous_tag_index is not None:\n",
        "                self._A[previous_tag_index][tag_index] += 1\n",
        "\n",
        "            previous_tag_index = tag_index\n",
        "\n",
        "      total_tags = self._Ï€.sum()\n",
        "      # Laplace smoothing\n",
        "      l = 0.5\n",
        "      self._Ï€ = (self._Ï€ + l) / (total_tags + l*len(tags_vocab))\n",
        "      self._A = (self._A + l) / (self._A.sum(axis=1, keepdims=True) + l*len(tags_vocab))\n",
        "      self._B = (self._B + l) / (self._B.sum(axis=1, keepdims=True) + l*len(words_vocab))\n",
        "\n",
        "      # TO DO ----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "  def inference(self, sentence: list) -> list[Tuple[str, str]]:\n",
        "      \"\"\"\n",
        "      Predicts the best tag sequence for a given input sentence using the Viterbi decoding algorithm.\n",
        "\n",
        "      Args:\n",
        "          sentence (list): The sentence to tag, as a list of words.\n",
        "\n",
        "      Returns:\n",
        "          List[Tuple[str, str]]: Each word in the input sentence paired with its predicted tag.\n",
        "      \"\"\"\n",
        "      # TO DO ----------------------------------------------------------------------\n",
        "      word_indices = [words_vocab.get(word, words_vocab['<<UNK>>']) for word in sentence] # get a list of the indices of each word in the sentence, or use 0 if not in the vocab\n",
        "      best_tag_indices = viterbi(word_indices, self._A, self._B, self._Ï€) # use viterbi to get the best tags indices for the list of word indices\n",
        "      best_tags = [list(tags_vocab.keys())[index] for index in best_tag_indices] # get a list of the actual tags using the indices\n",
        "      tagged_sentence = list(zip(sentence, best_tags)) # create a list of tuples of each word in the sentence with its predicted tag\n",
        "      return tagged_sentence\n",
        "\n",
        "      # TO DO ----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni-3uwVmXiKB"
      },
      "source": [
        "### Optional Task: Implement the Viterbi Algorithm\n",
        "Implement the `viterbi` function to perform POS tagging using the Viterbi decoding algorithm. This algorithm finds the most probable sequence of hidden states (POS tags in this case) given a sequence of observations (words in the sentence).\n",
        "\n",
        "### Instructions\n",
        "- **Pre-Implemented Code**: We provide a pre-implemented version of the Viterbi algorithm for your convenience. This implementation is fully functional and can be used directly in your HMM tagger.\n",
        "  \n",
        "- **Implementation Challenge**: Although a pre-implemented version is available, we encourage you to implement the Viterbi algorithm yourself. Doing so will help you understand the dynamics of dynamic programming in the context of POS tagging. Follow the pseudocode provided in the lecture slides to develop your own version of the algorithm.\n",
        "\n",
        "### Steps for Implementation\n",
        "1. **Understand the Pseudocode**: Review the pseudocode provided in the slides from the class. Ensure you understand each step of the algorithm, including how the probabilities are updated and the backtracking process to recover the state sequence.\n",
        "  \n",
        "2. **Implement the Function**: Using the pseudocode as a guide, write your own `viterbi` function. Consider the matrices (A, B, and Pi) you prepared in the HMMTagger class as inputs along with the sequence of observations (word indices for a sentence).\n",
        "  \n",
        "3. **Test Your Implementation**: After implementing the function, test it with known inputs to ensure it produces the correct sequence of tags. Compare the results with those obtained from the pre-implemented version to validate your implementation.\n",
        "\n",
        "### Additional Tips\n",
        "- **Handle Edge Cases**: Consider edge cases such as very short sentences, sentences containing many unknown words, and varying sentence structures.\n",
        "- **Optimization**: Once your basic implementation is correct, think about potential optimizations to improve the efficiency of your code, especially if you are processing large datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reimplemented viterbi, optimised using vectorised code to reduce use of for loops\n",
        "def viterbi(word_list: list, A: np.ndarray, B: np.ndarray, Pi: np.ndarray):\n",
        "    \"\"\"\n",
        "    Executes the Viterbi algorithm to find the most likely state sequence given a sequence of observations.\n",
        "\n",
        "    Args:\n",
        "        word_list (list): A list of indices corresponding to observed words.\n",
        "        A (numpy.ndarray): The state transition probability matrix of shape (num_states, num_states) where A[i][j] is the probability of transitioning from state i to state j.\n",
        "        B (numpy.ndarray): The emission probability matrix of shape (num_states, num_vocabulary) where B[i][j] is the probability of emitting symbol j from state i.\n",
        "        Pi (numpy.ndarray): The initial state probability vector of length num_states where Pi[i] is the probability of starting in state i.\n",
        "\n",
        "    Returns:\n",
        "        list: The most likely sequence of states (as indices) for the given sequence of observations.\n",
        "    \"\"\"\n",
        "    # Number of states\n",
        "    num_states = len(A)\n",
        "    # Length of the observed sequence\n",
        "    T = len(word_list)\n",
        "\n",
        "    # Create the path probability matrix V\n",
        "    V = np.zeros((T, num_states))\n",
        "    # Create a path backpointer matrix to store the argmax indices\n",
        "    path = np.zeros((T, num_states), dtype=int)\n",
        "\n",
        "    # Initialization step\n",
        "    V[0, :] = Pi * B[:, word_list[0]]\n",
        "\n",
        "    # Recursion step\n",
        "    for t in range(1, T):\n",
        "        for s in range(num_states):\n",
        "            # vectorized computation of the max transition probability\n",
        "            transition_probs = V[t-1, :] * A[:, s]\n",
        "            max_tr_prob = np.max(transition_probs)\n",
        "            prev_state_selected = np.argmax(transition_probs)\n",
        "\n",
        "            V[t, s] = max_tr_prob * B[s, word_list[t]]\n",
        "            path[t, s] = prev_state_selected\n",
        "\n",
        "    # Termination step\n",
        "    # Find the best path by looking for the maximum probability in the last column\n",
        "    opt = []\n",
        "    best_last_state = np.argmax(V[T-1, :])\n",
        "    opt.append(best_last_state)\n",
        "\n",
        "    # Follow the back pointers to decode the best path\n",
        "    previous = best_last_state\n",
        "    for t in range(T-1, 0, -1):\n",
        "        previous = path[t, previous]\n",
        "        opt.insert(0, previous)\n",
        "\n",
        "    return opt"
      ],
      "metadata": {
        "id": "UDrwuZCAjDB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bkj25vm2knij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28a1c84-159a-4392-b20e-c0b66fb25c24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Example for using Viterbi algorithm (from the course slides)\n",
        "A = np.array([[0.3, 0.7], [0.2, 0.8]])\n",
        "B = np.array([[0.1, 0.1, 0.3, 0.5], [0.3, 0.3, 0.2, 0.2]])\n",
        "Pi = np.array([0.4, 0.6])\n",
        "\n",
        "viterbi([0, 3, 2, 0], A, B, Pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnKUWMhyUgXy"
      },
      "source": [
        "## Train & Evaluate\n",
        "\n",
        "## Task: Implement the Train and Evaluate Tagger Function\n",
        "\n",
        "### Function Specification\n",
        "Create a function named `train_evaluate_tagger` that combines the training and evaluation processes for a tagging algorithm. This integrated function should:\n",
        "- **Input**:\n",
        "  - **tagger** (`HMMTagger` or `EmbeddingsTagger`): The POS tagger to be trained and evaluated.\n",
        "  - **train_dataset** (`List[List[Tuple[str, str]]]`): The dataset on which the tagger will be trained. Training is executed only if the `train` flag is set to True.\n",
        "  - **eval_dataset** (`List[List[Tuple[str, str]]]`): The dataset used for evaluating the tagger's performance.\n",
        "  - **train** (`bool`): A boolean flag indicating whether the training phase should be executed. If set to True, the `fit` method of the tagger will be called before evaluation.\n",
        "- **Functionality**:\n",
        "  - Train the tagger using the `train_dataset`.\n",
        "  - Evaluate the trained tagger on the `test_dataset` to compute performance metrics.\n",
        "  - Return the following evaluation metrics: accuracy, precision, recall, and F1-score.\n",
        "- **Outputs**: A tuple consisting of three elements: precision, recall, F1-score, as returned by the `precision_recall_fscore_support` function from the `sklearn.metrics` module, when called with the parameter `average=\"macro\"`.\n",
        "* Note the the support metric is missed (Why?).\n",
        "\n",
        "\n",
        "### Evaluation Metrics\n",
        "Upon execution, the `train_evaluate_tagger` function provides the following metrics:\n",
        "- **Macro-average Precision, Recall, and F1 Score**: These scores are calculated over all tags to assess the overall effectiveness of the tagger in recognizing the correct tags across different types of words.\n",
        "- **Performance Breakdown by Tag**: Detailed metrics for each tag, helping to identify which tags are most and least accurately predicted.\n",
        "- **Overall Word-Level Accuracy**: Measures the percentage of words correctly tagged by the tagger across the entire evaluation dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vumzm2lB7p1-"
      },
      "outputs": [],
      "source": [
        "def train_evaluate_tagger(tagger, train_dataset: DataType=train_dataset, eval_dataset: DataType=test_dataset, train=True):\n",
        "    \"\"\"\n",
        "    Trains (optional) and evaluates a POS tagger, returning performance metrics.\n",
        "\n",
        "    This function trains the given tagger if specified, and evaluates it on a provided dataset.\n",
        "    It calculates and returns the macro-average precision, recall, and F1-score.\n",
        "\n",
        "    Args:\n",
        "        tagger (HMMTagger or EmbeddingsTagger): The POS tagger to be trained and evaluated.\n",
        "        train_dataset (List[List[Tuple[str, str]]]): The dataset to train the tagger.\n",
        "        eval_dataset (List[List[Tuple[str, str]]]): The dataset to evaluate the tagger.\n",
        "        train (bool): A flag indicating whether the tagger should be trained.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing average precision, recall, and F1-score.\n",
        "\n",
        "    The function also prints a classification report for detailed performance analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    true_tags = []\n",
        "    predicted_tags = []\n",
        "\n",
        "    # TO DO ----------------------------------------------------------------------\n",
        "    if train:\n",
        "        tagger.fit(train_dataset)\n",
        "\n",
        "    true_tags = []\n",
        "    predicted_tags = []\n",
        "\n",
        "    for sentence in eval_dataset:\n",
        "        words, tags = zip(*sentence) # seperate the sentence into lists of words and pos tags\n",
        "        predicted_sentence = tagger.inference(list(words))  # get the tupled words and predicted tags\n",
        "        _, predicted_tags_sentence = zip(*predicted_sentence)  # extract just the predicted tags\n",
        "\n",
        "        true_tags.extend(tags) # add the correct tags from the eval set to the true tags list\n",
        "        predicted_tags.extend(predicted_tags_sentence) # add the predicted tags from the eval set to the predicted tags list\n",
        "\n",
        "    # TO DO ----------------------------------------------------------------------\n",
        "    # Compute precision, recall, F1-score, and support for each class\n",
        "    precision, recall, f1_score, support = precision_recall_fscore_support(true_tags, predicted_tags, average=None)\n",
        "\n",
        "    # Display classification report\n",
        "    report = classification_report(true_tags, predicted_tags)\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Return the macro-average metrics\n",
        "    avg_precision, avg_recall, avg_f1, _ = precision_recall_fscore_support(true_tags, predicted_tags, average='macro')\n",
        "\n",
        "    return avg_precision, avg_recall, avg_f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0uM2tozQmpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f259366-9d02-4123-aabc-cec61a89fb4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     <<UNK>>       0.00      0.00      0.00         0\n",
            "         ADJ       0.82      0.80      0.81      1622\n",
            "         ADP       0.88      0.97      0.92      2481\n",
            "         ADV       0.85      0.78      0.82      1114\n",
            "         AUX       0.81      0.97      0.88      1189\n",
            "       CCONJ       0.96      0.97      0.97       839\n",
            "         DET       0.86      0.97      0.91      2111\n",
            "        INTJ       0.67      0.69      0.68       163\n",
            "        NOUN       0.88      0.83      0.85      4239\n",
            "         NUM       0.78      0.70      0.74       440\n",
            "        PART       0.82      0.81      0.82       519\n",
            "        PRON       0.83      0.98      0.90      1746\n",
            "       PROPN       0.82      0.56      0.67      1628\n",
            "       PUNCT       0.93      1.00      0.96      3027\n",
            "       SCONJ       0.78      0.56      0.65       340\n",
            "         SYM       0.58      0.40      0.47        35\n",
            "        VERB       0.88      0.79      0.83      2480\n",
            "           X       0.56      0.16      0.24        32\n",
            "\n",
            "    accuracy                           0.86     24005\n",
            "   macro avg       0.76      0.72      0.73     24005\n",
            "weighted avg       0.86      0.86      0.86     24005\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Train (optional) and Evaluate your HMMTagger here\n",
        "hmmTagger = HMMTagger()\n",
        "precision_hmm, recall_hmm, f1_hmm = train_evaluate_tagger(hmmTagger)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(precision_hmm)\n",
        "print(recall_hmm)\n",
        "print(f1_hmm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIil-qzvt_VN",
        "outputId": "ef39105d-6b42-4ca7-8456-948943a0fa39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.761346742815566\n",
            "0.7182275895674305\n",
            "0.7287772388968269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3fPdEWBetDE"
      },
      "source": [
        "## Part 3 - POS Tagging with Pre-trained Word Embeddings\n",
        "\n",
        "### Task Overview\n",
        "Develop a feed-forward neural network for Part-of-Speech (POS) tagging using the PyTorch framework. This tagger leverages pre-trained word embeddings from the word2vec Google News dataset, enhancing the semantic understanding of words compared to traditional tagging methods.\n",
        "\n",
        "### Task 1: Initialization of Embeddings (`init_embeddings`)\n",
        "Create an `init_embeddings` method within the `EmbeddingsTagger` class to load and set up pre-trained word embeddings:\n",
        "- Load the Google News word vectors from a specified file path.\n",
        "- Initialize a matrix to hold these embeddings where each word in your vocabulary is represented by a vector. For words not in the pre-trained model, initialize their vectors randomly.\n",
        "-  <font color='red'>**NOTE:** Before you start implementing the init_embeddings method, make sure to create your own copy of the pre-trained embeddings (.bin file) in your Google Drive from [the following Google Drive folder](https://drive.google.com/drive/folders/1-HcSBfqaX0PCFiT8TsiYjFZRQJRm2R5v?usp=sharing). You will need to use the gensim library to load this file.</font>\n",
        "\n",
        "### Task 2: Implementation of `EmbeddingsTagger` Class\n",
        "Extend PyTorch's `nn.Module` to implement the `EmbeddingsTagger` class. This class should utilize the embeddings matrix and include:\n",
        "- An embedding layer that is initialized with the pre-trained embeddings.\n",
        "- A linear layer to combine embeddings of the current and previous words with a one-hot encoded previous tag to predict the current tag.\n",
        "- A `forward` method that outlines the data flow through the network.\n",
        "\n",
        "### Task 3: Model Training and Evaluation (`fit` and `inference` Methods)\n",
        "Implement training and inference functionalities within the `EmbeddingsTagger` class:\n",
        "- **Train Method (`fit`)**: Set up the model training using the specified training dataset. This includes iterating through the dataset, applying the model to predict tags, and updating model parameters based on the loss computation.\n",
        "- **Inference Method (`inference`)**: Configure the model to predict tags on a new dataset, assessing the model's effectiveness on unseen data.\n",
        "\n",
        "### Model Performance Monitoring\n",
        "Utilize the `train_evaluate_tagger` function to oversee the training process and evaluate the model:\n",
        "- Configure this function to handle model training with appropriate optimizer and loss settings.\n",
        "- Monitor and report the model's performance metrics during training and on a test dataset to ensure effective tagging.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOGqtQtyUsA9"
      },
      "source": [
        "### Google News pre-trained embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XROdy8sHZ-Qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84dcbfa1-787a-442c-aec1-5aa71b5b44fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsTagger(nn.Module):\n",
        "    def __init__(self, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        Initializes an embeddings-based POS tagger that uses word embeddings from a pre-trained model.\n",
        "\n",
        "        Args:\n",
        "            device (str): The device (cpu or cuda) the model should operate on for tensor operations.\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        super(EmbeddingsTagger, self).__init__()\n",
        "        self.embedding_dim = 300  # Dimension of Google News embeddings\n",
        "        self.tagset_size = len(tags_vocab)\n",
        "        self.word_embeddings = self.init_embeddings()\n",
        "        self.to(device)\n",
        "\n",
        "\n",
        "        # The input dimension to the linear layer is twice the embedding_dim (for two words)\n",
        "        # plus tagset_size (for the one-hot encoded previous tag)\n",
        "        self.linear_layer = nn.Linear(2 * self.embedding_dim + self.tagset_size, self.tagset_size).to(self.device)\n",
        "\n",
        "\n",
        "    def init_embeddings(self) -> nn.Embedding:\n",
        "        \"\"\"\n",
        "        Loads word embeddings from a pre-trained Google News model and initializes an embedding layer.\n",
        "\n",
        "        Returns:\n",
        "            nn.Embedding: A PyTorch embedding layer with the pre-trained word embeddings.\n",
        "        \"\"\"\n",
        "        # Specify the path to the Google News model in your Google Drive\n",
        "        path_to_google_news_vectors = '/content/drive/My Drive/GoogleNews-vectors-negative300.bin'\n",
        "\n",
        "        # Load Google News Vectors\n",
        "        model = gensim.models.KeyedVectors.load_word2vec_format(path_to_google_news_vectors, binary=True)\n",
        "\n",
        "        # Prepare a matrix to hold the embeddings\n",
        "        embedding_matrix = np.zeros((len(words_vocab), 300))  # Ensure 'words_vocab' maps words to indices, 300 is the dimension of embeddings\n",
        "\n",
        "        # TO DO ----------------------------------------------------------------------\n",
        "        for word, idx in words_vocab.items():\n",
        "            if word in model:\n",
        "                embedding_matrix[idx] = model[word]\n",
        "            else:\n",
        "                embedding_matrix[idx] = np.random.normal(scale=0.6, size=(self.embedding_dim))\n",
        "\n",
        "        #embedding_matrix = th.tensor(embedding_matrix, dtype=th.float)\n",
        "        embedding_layer = nn.Embedding.from_pretrained(th.tensor(embedding_matrix, dtype=th.float), freeze=True)\n",
        "        #embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        return embedding_layer\n",
        "\n",
        "        # TO DO ----------------------------------------------------------------------\n",
        "\n",
        "    def forward(self, current_word_index: int, previous_word_index: int, prev_tag_one_hot: th.Tensor):\n",
        "        \"\"\"\n",
        "        Forward pass of the tagger to compute logits for each tag.\n",
        "\n",
        "        Args:\n",
        "            current_word_index (int): Index of the current word in the vocabulary.\n",
        "            previous_word_index (int): Index of the previous word in the vocabulary.\n",
        "            prev_tag_one_hot (th.tensor): One-hot encoded tensor of the previous tag.\n",
        "\n",
        "        Returns:\n",
        "            th.tensor: Log probabilities for each tag.\n",
        "        \"\"\"\n",
        "        # TO DO ----------------------------------------------------------------------\n",
        "        current_word_embedding = self.word_embeddings(th.tensor([current_word_index], device=self.device))\n",
        "        previous_word_embedding = self.word_embeddings(th.tensor([previous_word_index], device=self.device))\n",
        "\n",
        "        current_word_embedding = current_word_embedding.view(1, -1)  # Ensure it is 2D\n",
        "        previous_word_embedding = previous_word_embedding.view(1, -1)  # Ensure it is 2D\n",
        "        prev_tag_one_hot = prev_tag_one_hot.view(1, -1)  # Ensure it is 2D\n",
        "\n",
        "        combined = th.cat((current_word_embedding, previous_word_embedding, prev_tag_one_hot), dim=1)\n",
        "        tag_space = self.linear_layer(combined)\n",
        "        tag_scores = th.log_softmax(tag_space, dim=1)\n",
        "\n",
        "        return tag_scores\n",
        "        # TO DO ----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    def fit(self, dataset=list(train_dataset), epochs=4):\n",
        "        \"\"\"\n",
        "        Trains the tagger on the provided dataset for a specified number of epochs.\n",
        "\n",
        "        Args:\n",
        "            dataset (list): The dataset to train the model on.\n",
        "            epochs (int): Number of training epochs.\n",
        "        \"\"\"\n",
        "        loss_function = nn.NLLLoss()\n",
        "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "        # preparing instances for training\n",
        "        instances = []\n",
        "\n",
        "        # TO DO ----------------------------------------------------------------------\n",
        "        for sentence in dataset:\n",
        "          words, tags = zip(*sentence)\n",
        "          for i in range(1, len(words)):\n",
        "              current_word = words[i]\n",
        "              previous_word = words[i-1]\n",
        "              prev_tag = tags[i-1]\n",
        "              target_tag = tags[i]\n",
        "\n",
        "              current_word_idx = words_vocab.get(current_word, 0)\n",
        "              previous_word_idx = words_vocab.get(previous_word, 0)\n",
        "              prev_tag_one_hot = th.zeros(self.tagset_size, device=self.device)\n",
        "\n",
        "              if prev_tag in tags_vocab:\n",
        "                    prev_tag_one_hot[tags_vocab[prev_tag]] = 1\n",
        "              target_tag_idx = th.tensor([tags_vocab[target_tag]], device=self.device)  # Ensure it is a single-element tensor\n",
        "\n",
        "              instances.append((current_word_idx, previous_word_idx, prev_tag_one_hot, target_tag_idx))\n",
        "        # TO DO ----------------------------------------------------------------------\n",
        "\n",
        "        loss_c = 0\n",
        "        for epoch in range(epochs):\n",
        "          for index, (current_word, previous_word, prev_tag_one_hot, target_tag) in enumerate(instances):\n",
        "            self.zero_grad()\n",
        "            tag_scores = self(current_word, previous_word, prev_tag_one_hot)\n",
        "            loss = loss_function(tag_scores, target_tag)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_c += loss.item()\n",
        "            # Add printing (logging) as you wish (loss, epochs, etc.)\n",
        "\n",
        "\n",
        "    def inference(self, sentence: list) -> List[Tuple[str, str]]:\n",
        "        \"\"\"\n",
        "        Predicts the tags for each word in a given sentence.\n",
        "\n",
        "        Args:\n",
        "            sentence (list): The sentence to tag, given as a list of words.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of tuples containing each word and its predicted tag.\n",
        "        \"\"\"\n",
        "\n",
        "        # TO DO ----------------------------------------------------------------------\n",
        "        tagged_sentence = []\n",
        "        prev_tag = '<START>'\n",
        "        prev_word = '<START>'\n",
        "        for word in sentence:\n",
        "            current_word_index = words_vocab.get(word, 0)\n",
        "            previous_word_index = words_vocab.get(prev_word, 0)\n",
        "            prev_tag_one_hot = th.zeros(self.tagset_size, device=self.device)\n",
        "\n",
        "            if prev_tag in tags_vocab:\n",
        "                  prev_tag_one_hot[tags_vocab[prev_tag]] = 1\n",
        "            tag_scores = self.forward(current_word_index, previous_word_index, prev_tag_one_hot)\n",
        "\n",
        "            predicted_tag_index = th.argmax(tag_scores, dim=1).item()\n",
        "            predicted_tag = list(tags_vocab.keys())[predicted_tag_index]\n",
        "\n",
        "            tagged_sentence.append((word, predicted_tag))\n",
        "\n",
        "            prev_tag = predicted_tag\n",
        "            prev_word = word\n",
        "\n",
        "        return tagged_sentence\n",
        "        # TO DO ----------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "xdO_o7r06VSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_IoQJ2PXOaZ"
      },
      "outputs": [],
      "source": [
        "# Initialize the model with pre-trained embeddings\n",
        "device = th.device(\"cuda\")\n",
        "embeddings_tagger = EmbeddingsTagger(device=device)\n",
        "#embeddings_tagger = EmbeddingsTagger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IDlGSTbd-CZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c543a4-0ccc-415c-bbb0-d027096efb60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.81      0.77      0.79      1622\n",
            "         ADP       0.89      0.90      0.89      2481\n",
            "         ADV       0.78      0.72      0.75      1114\n",
            "         AUX       0.93      0.92      0.92      1189\n",
            "       CCONJ       0.69      0.98      0.81       839\n",
            "         DET       0.97      0.93      0.95      2111\n",
            "        INTJ       0.82      0.20      0.32       163\n",
            "        NOUN       0.88      0.89      0.89      4239\n",
            "         NUM       0.65      0.72      0.68       440\n",
            "        PART       0.83      0.84      0.83       519\n",
            "        PRON       0.92      0.88      0.90      1746\n",
            "       PROPN       0.88      0.63      0.73      1628\n",
            "       PUNCT       0.89      1.00      0.94      3027\n",
            "       SCONJ       0.51      0.51      0.51       340\n",
            "         SYM       0.39      0.60      0.47        35\n",
            "        VERB       0.84      0.88      0.86      2480\n",
            "           X       0.21      0.09      0.13        32\n",
            "\n",
            "    accuracy                           0.86     24005\n",
            "   macro avg       0.76      0.73      0.73     24005\n",
            "weighted avg       0.86      0.86      0.86     24005\n",
            "\n"
          ]
        }
      ],
      "source": [
        "precision_embeddings, recall_embeddings, f1_embeddings = train_evaluate_tagger(embeddings_tagger)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(precision_embeddings)\n",
        "print(recall_embeddings)\n",
        "print(f1_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDzh7TYpuMoC",
        "outputId": "97a3839d-a103-4879-c6d1-2f5e85603433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7658343873010054\n",
            "0.785875590941914\n",
            "0.7635229207100354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YZO0uGL-4S-"
      },
      "source": [
        "\n",
        "# Part 4 - NLTK Tagger\n",
        "\n",
        "### Overview\n",
        "In this final part of the assignment, you will evaluate the performance of the HMM-based and feed-forward taggers you developed against a Maximum Entropy Markov Model (MEMM) tagger implemented using the Natural Language Toolkit (NLTK), a popular NLP library. Perform comparison should cover the test dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl3oahPVpsBt"
      },
      "source": [
        "#### Step 1: Training the MEMM Tagger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmkNPYzOvDdf"
      },
      "outputs": [],
      "source": [
        " # TO DO ----------------------------------------------------------------------\n",
        "memm_tagger = tnt.TnT()\n",
        "memm_tagger.train(train_dataset)\n",
        " # TO DO ----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ8YwpiyvJ6l"
      },
      "source": [
        "#### Step 2: Evaluation\n",
        "- Evaluate the trained MEMM tagger on  the test dataset.\n",
        "- Calculate performance metrics such as accuracy, and F1-score. NLTK provides utilities that can help compute these metrics efficiently.\n",
        "- Save & Print the eveluation scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_tagger(tagger, test_sents):\n",
        "    true_tags = []\n",
        "    predicted_tags = []\n",
        "\n",
        "    for sentence in test_sents:\n",
        "        words, tags = zip(*sentence)\n",
        "        predicted_sentence = tagger.tag(words)\n",
        "        predicted_tags_sentence = [tag for word, tag in predicted_sentence]\n",
        "\n",
        "        true_tags.extend(tags)\n",
        "        predicted_tags.extend(predicted_tags_sentence)\n",
        "\n",
        "    return true_tags, predicted_tags\n",
        "\n",
        "true_tags, predicted_tags = evaluate_tagger(memm_tagger, test_dataset)"
      ],
      "metadata": {
        "id": "A9V6ZofxgdBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnw1UbMj1n3f"
      },
      "outputs": [],
      "source": [
        " # TO DO ----------------------------------------------------------------------\n",
        " # Accurcy\n",
        "accuracy_tnt_pos_tagger = nltk.accuracy(true_tags, predicted_tags)\n",
        "print(round(accuracy_tnt_pos_tagger,2))\n",
        " # TO DO ----------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-7FX8tW0y7k"
      },
      "outputs": [],
      "source": [
        "# TO DO ----------------------------------------------------------------------\n",
        "# F-measure for each tag\n",
        "from nltk.metrics import ConfusionMatrix\n",
        "cm = ConfusionMatrix(true_tags, predicted_tags)\n",
        "for tag in set(true_tags):\n",
        "  tag_f_measure = round(cm.f_measure(tag),2)\n",
        "  print(f'{tag}\\t{tag_f_measure}')\n",
        "\n",
        "# TO DO ----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other metrics for evaluation and comparison\n",
        "print(cm.evaluate)"
      ],
      "metadata": {
        "id": "QlfwxLo70EW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG4PmdJ_qRHi"
      },
      "source": [
        "# Evaluatoin and Comparison\n",
        "Compare the results obtained from the MEMM tagger with those from your HMM and feed-forward neural network taggers.\n",
        "\n",
        "This part won't be tested by the autograder.\n",
        "\n",
        "#### Discuss the following:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXpQoDsdqihY"
      },
      "source": [
        "\n",
        "* <font color='red'>(**?**)</font> Which tagger performed best on each dataset and why?\n",
        "* <font color='green'>(**Answer**)</font> : The MEMM tagger using NLTK performed best. This is likely because the NLTK tagger is more finely-tuned, and is a discriminative model that decides on conditional probabilities based on observation, whereas the HMM and embeddings tagger modeled the joint probabilities of the observation as well as the tag sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SgZs91PqyIG"
      },
      "source": [
        "* <font color='red'>(**?**)</font> What are the strengths and weaknesses of each approach (HMM, feed-forward neural network, MEMM) in terms of training time, accuracy, and generalizability?\n",
        "* <font color='green'>(**Answer**)</font> : Strengths and weaknesses of each model:\n",
        "\n",
        "HMM: relatively fast training time but lower accuracy compared with more complex models such as a neural network.  Limited generalizability.\n",
        "Feed-forward neural network:  require longer training time which can also greatly increase if we increase the size of the network. A feed-forward neural network can achieve high accuracy, but may overfit the training data which can lead to poor generalizability.\n",
        "MEMM: High accuracy and moderate training time. Can have high generalizability but like HMM suffers from label bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q9_TVEPUKkO"
      },
      "source": [
        "# Testing\n",
        "Copy the content of the **tests.py** file from the repo and paste below. This will create the results.json file and download it to your machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJgUy9qNUE0l"
      },
      "outputs": [],
      "source": [
        "####################\n",
        "# PLACE TESTS HERE #\n",
        "\n",
        "def test_read_data_data_types():\n",
        "    data = read_data(\"UD_English-GUM/en_gum-ud-train.conllu\")\n",
        "    result = {\n",
        "        'is_data_list': type(data) == list,\n",
        "        'is_data_first_element_list': type(data[0]) == list,\n",
        "        'is_data_first_element_first_item_tuple': type(data[0][0]) == tuple\n",
        "    }\n",
        "    return result\n",
        "\n",
        "def test_read_data_len_train_data():\n",
        "    return {\n",
        "        'train_data_length': len(read_data(\"UD_English-GUM/en_gum-ud-train.conllu\")),\n",
        "    }\n",
        "\n",
        "def test_generate_vocabs():\n",
        "    return {\n",
        "        'vocab_size': len(words_vocab),\n",
        "        'num_tags': len(tags_vocab)\n",
        "    }\n",
        "\n",
        "def test_hmm():\n",
        "    return {\n",
        "        'precision': round(precision_hmm, 2),\n",
        "        'recall': round(recall_hmm, 2),\n",
        "        'f1': round(f1_hmm, 2),\n",
        "    }\n",
        "\n",
        "def test_embeddings_model():\n",
        "    return {\n",
        "        'precision': round(precision_embeddings, 2),\n",
        "        'recall': round(recall_embeddings, 2),\n",
        "        'f1': round(f1_embeddings, 2),\n",
        "    }\n",
        "\n",
        "\n",
        "def test_nltk_tagger():\n",
        "    return {\n",
        "        'accuracy': round(accuracy_tnt_pos_tagger, 2)\n",
        "    }\n",
        "\n",
        "TESTS = [test_read_data_data_types, test_read_data_len_train_data, test_generate_vocabs, test_hmm, test_embeddings_model, test_nltk_tagger]\n",
        "\n",
        "# Run tests and save results\n",
        "res = {}\n",
        "for test in TESTS:\n",
        "    try:\n",
        "        cur_res = test()\n",
        "        res.update({test.__name__: cur_res})\n",
        "    except Exception as e:\n",
        "        res.update({test.__name__: repr(e)})\n",
        "\n",
        "with open('results.json', 'w') as f:\n",
        "    json.dump(res, f, indent=2)\n",
        "\n",
        "# Download the results.json file\n",
        "files.download('results.json')\n",
        "\n",
        "####################"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}